# JobListingAggregator
This public repository contains the development process for a set of microservices designed to periodically gather job listings from various job sites, formatted and pre-filtered by configurable user rules.
More specifically, this is a demonstration project I have created to fulfill three goals:
1. To establish a set of microservices to ease my ongoing job search, in a way that does not put undue strain on the job sites I will be pulling from.
2. To push myself to learn new technologies; I am familiar with C#, but RabbitMQ, Avalonia, and XAML are all new to me as of the start of this project. In fact, I am using these three because they are new to me. There are less complex ways to implement goal #1 if that was all I wanted.
3. To demonstrate, via this repository, that I can code competently and efficiently with languages that I am still learning on the fly.

That said, I have already constructed a very rough prototype to prove feasibility prior to the creation of this repository, so I'm not going in blind. This will come in five parts.
1. The RabbitMQ installation, which will by and large exist outside of this repository. This messaging software will handle all of the communication between any number of instances of the following components. I'm not developing this, it's an existing application, I'm merely using it.
2. The 'JLA-Client' project, which will compile to a single desktop GUI application and communicate with the RabbitMQ installation. This will be the face of the program for users, with an interactive GUI and a configuration file to allow for changing settings per instance. Normal users will only interact with this portion of the project.
3. The 'JLA-Backend' project, which will compile to a single desktop command line application and communicate with the RabbitMQ installation. This component of the project will do the work of retrieving job listings on demand and applying pre-filters to cut down on the number it has to send back to the client that requested them. There can be one or many instances of this component, the messaging service will distribute incoming requests among them.
4. The 'JLA-Logger' project, which will compile to a single desktop command line application and communicate with the RabbitMQ installation. This component will be able to track all or some (configurable) of the log messages both the JLA-Client and JLA-Backend will be broadcasting through the messaging service, to allow for overall or granular logging independent of the other components.
5. The 'JLA-Unified', which will be a program seperate from the others, meant to combine the functionality of components 2 and 3 while eschewing the need for components 1 and 4 outright. This would be the 'right way' to do it if I were solely interested in goal #1 - a local program that does the work of the Backend within the Client. Thus I am including it here for niche use cases where communication with RabbitMQ is infeasible... and to demonstrate that I do know the rest of this project is intentionally complex in its architecture.

I have also considered creating a sixth component with the ability to issue meta-commands to specific instances of the Backend, Client, or Logger components (e.g. shut down instance x of JLA-Backend), but at the time of writing do not consider this necessary within the scope of my own project. Specifcally... Until and unless I reach the point of stress-testing my design with many clients, backends, etc, just for the fun of it, I'm not going to need software that manages my other software.

Components 2-5 will have configuration files outside of their executables, to allow for users to configure their instances. Things like the specific names for RabbitMQ Queues, for instance, or the frequency of automatic saving of data. Component 2, the Client, will additionally save and load data that persists through sessions; the sets of 'rules' dictating what requests are automatically sent out to the Backend, and the running list of jobs themselves. These will be saved in the default locations for desktop application data (e.g. a subfolder within .config, if we're talking Linux Mint)

Components 2-5 will have independent executable files for Linux (Mint) and Windows, as the bare minimum to be considered complete. These are the environments I have access to for easy testing, and thus the ones I am developing for.

The JLA-Backend will poll supported job sites through one of three means, in order from most to least desirable:
1. Through a provided API or other official interface. (Right now, absolutely none of the sites I'm looking at have easily accessible APIs for retrieving job listings, so this isn't going to happen... which is unfortunate, since the vast majority of my professional programming experience is working with APIs of all stripes.)
2. Through calling the site like a browser would and parsing the result to filter out the data I want. (String munging is NOT as reliable as I'd like, and prone to rapid decay as the sites being munged make changes, but it does work so long as I assume, and then follow through with, ongoing maintenance.) In this scenario I will not call any site more often or more quickly than a normal human could reasonably do. I also will not attempt to bypass anti-bot measures, such as captcha. These are design requirements, and honestly, not hard to adhere to. The internal latency of job site postings mean that I'm already dealing with 30+ minute delays on new postings even if I retrieve new job listings instantly (aka I retrieve a listing that went up on the site less than a minute ago, but the listing was 'published' 45 minutes ago according to their own data). Calling once every half-hour is thus no sacrifice at all.
3. If in no other way, by generating a single 'dummy' job listing to send back to the client, which represents the search they wanted to perform as a formatted link where the link to the specific job posting would otherwise reside. In this way, even the most uncooperative site can still at least be manually viewed with a reminder to do so as often as the client would otherwise like it to be automatically parsed.

Proper development of this project will commence on 05/22/2025 at 8AM, and will continue for 8 hours per day until I deem the project complete, at which point it will enter maintenance and ongoing additional development mode. (I'll keep it working, bugfix, and add any additional features I want as I use it). Upkeep / maintenance / bugfixing will continue until I have a job and probably well beyond that point.

At no point was AI used in this process; I'm doing this to learn and to demonstrate my own ability, and relying upon AI in any capacity would rather defeat the point.